Team Report:
============

Previous Week’s Goals
---------------------

*   Finalize CI service we will use **(everyone)**
    
*   Frontend:
    
    *   Set up app structure **(Sulaiman)**
        
    *   Set up app navigation **(Sulaiman)**
        
*   Backend:
    
    *   Set up API endpoints/structure **(Sulaiman, Aneesha)**
        
*   CV:
    
    *   Create/find small testing dataset **(Aaron)**
        
        *   2 days, done by Friday 2/2
            
    *   Get a working CV model **(Victor)**
        
        *   Test pre-trained models manually **(Aaron)**
            
            *   2 days, done by Monday 2/5
                
        *   Start fine-tuning if needed
            
            *   Find dataset
                
                *   2 days, done by Wednesday 2/7
                    
            *   Training
                
                *   3 days, done by Friday 2/9
                    
*   ML:
    
    *   Setup LLM access **(Aneesha)**
        
        *   Find a service that we can use and set up API access
            
        *   Or find something we can run locally
            
    *   Create initial prompt for waste classification from object type **(Aneesha)**
        

Meeting Agenda
--------------

*   Scrum stand-up (5 min)
    
*   Questions (10-15 min)
    
    *   Demo tips?
        

Progress and Issues
-------------------

This week we’ve made significant progress on the frontend and in CV. We also have some progress for the backend and the ML.

In the frontend we were able to get some of the main parts of the application working including a stretch goal. The application now renders a camera right when it's opened. We added a button to capture a picture like a real phone and then displayed that photo under the camera interface. We added a search box along with a designed title for RecycleRight and made sure they are aligned correctly. The next step is to have the photo captured show in a separate interface after a loading screen, eventually we will stamp that photo or add some indication of where to recycle. Next steps are also to add a back button to go back to the camera after you get some results, along with making sure there is a reverse button for the camera and that everything aligns even when you hold the phone horizontally. Most importantly, sending the picture efficiently for the cv model is also next.

For our CV model, we have been training and testing models. Victor transformed a publicly available trash dataset into something we can use to train models. One model was trained from scratch and didn’t have great performance, but another model is in progress that will use transfer learning to improve the accuracy. We also created a small dataset to use for testing our CV model (along with the LLM) which consists of about 30 images labeled as recycle, compost, landfill, or other which we will feed into our algorithm to evaluate its results.

On the backend, we made some progress by finishing up the CI setup and figuring out an issue with our python setup.

In the ML space, we have been researching various available APIs and open-source models to decide what we should use, and we are close to setting up our LLM access.

Plans and Goals
---------------

*   Beta release, due 2/13
    
*   Frontend:
    
    *   Add next elements to the UI explained above (Sulaiman)
        
        *   2 days, due 2/9
            
    *   Use endpoints w/ some sort of classification can be a dummy (Sulaiman)
        
        *   3 days, due 2/10
            
*   Backend:
    
    *   Set up API structure  (Sulaiman)
        
        *   1 day, due 2/8
            
    *   Attach CV model and LLM to server
        
        *   2 days, due 2/10
            
    *   Set up hosting and CD (Aaron)
        
        *   2 days, due 2/12
            
    *   Create tests with images (Aaron)
        
        *   1 day, due 2/10
            
*   CV:
    
    *   Continue training and improving CV models (Victor)
        
        *   3 days, due 2/11
            
*   ML:
    
    *   Finalize LLM access, through api or local hosting (Aneesha)
        
        *   3 days, due 2/11
            
    *   More testing and prompt engineering
        

Individual Reports:
===================

Sulaiman:
---------

### Previous Week’s Goals

*   Setup app structure, due by Sunday 2/4
    
    *   Split our application into Flutter components which each might be a different file, and there will be a main file/component that will be in charge of the navigation of other components
        
*   Setup main page, due by Monday 2/5
    
    *   Implement the main page which will be a camera interface the moment the app opens
        
    *   Include a title and any other small design elements
        
*   Set up Endpoints?
    
*   Improve UI design?
    

### Progress and Issues

In the frontend, I was able to get some of the main parts of the application working, including a part of a stretch goal. The application now renders a camera right when it's opened. I added a button to capture a picture like a real phone and then displayed that photo under the camera interface (this will change). I also added a search box along with a designed title for RecycleRight and made sure they are aligned correctly. The next step is to have the photo captured show in a separate interface after a loading screen. Eventually, we will stamp that photo or add some indication of where to recycle. Future steps also include adding a back button to return to the camera after getting some results, along with making sure there is a reverse button for the camera and that everything aligns even when holding the phone horizontally. Most importantly, sending the picture efficiently for the CV model is also on the agenda. 

### Plans and Goals

*   Frontend (due Thursday/Friday):
    
    *   Add transition to show photo in another interface w/ loading screen 
        
    *   Add back button, reverse button, ensuring alignment
        
    *   Save image so it can be fed into model
        
    *   Use API endpoints w/ POST requests
        
*   Backend (due Thursday/Friday)
    
    *   Define and create API endpoints routes for classify image, classify text, and report classification and document the JSON structure
        
    *   Test these endpoints
        

Aneesha:
--------

### Previous Week’s Goals

*   Set up our backend test structure (1 day, by Thursday)
    
*   Set up API endpoints (3 days, by Saturday)
    
*   Set up LLM access
    
    *   Find a service that we can use and set up API access (3 days, by Tuesday)
        

### Progress and Issues

This week I worked on setting up the backed testing structure as well as setting up GitHub actions for the backend so that the backend code will build and the backend tests will be run automatically on the code. I also did research on the possible open-source LLMs we can use, as ChatGPT was not free, and decided on Mistral. I started looking into the documentation for and setting up Mistral. I do not have any particular issues right now, as I just need to continue working on setting up the LLM access, which took longer than anticipated due to balancing studying for midterms.

### Plans and Goals

*   Finalize LLM access, through api or local hosting (3 days, due 2/11)
    

Aaron:
------

### Previous Week’s Goals

*   Create a small CV testing dataset, due by Friday 2/2
    
    *   Find about 100 images of common waste items and label each with their waste type in a standard format
        
    *   Will be used later for validation of our algorithm.
        
*   Test pre-trained object detection models, due by Monday 2/3
    
    *   Use the CV testing dataset to manually run detection and pass results to ChatGPT
        
    *   Determine if the categories of the pre-trained models will be suitable for our needs
        

### Progress and Issues

This week I worked on creating a testing dataset to allow us to set up tests for our backend. So far I have gathered about 30 images and labeled them as recycle, compost, landfill, or other. These images were taken from google searches, but I plan on adding images that I take from my daily life and also just generally expanding this dataset.

I also did some testing with several of these images on one of the models that Victor trained. This model was the one that was trained from scratch, and it wasn’t able to identify most of the pictures that I tried, likely due to the large difference in context for the objects and the small training set size for the model.

We determined during our research and testing this past week that most general purpose pre-trained models won’t fit our purposes well because they are much more focused on common objects such as animals, people, cars, etc, whereas we need categories that are based on actual waste items.

I also spent a bit of time this week fixing some issues with our python venv that was committing macOS python binaries to our repo and preventing windows machines from using the venv.

### Plans and Goals

*   Set up hosting and CD for backend
    
    *   Create AWS EC2 instance for staging
        
    *   Set up CD to deploy on git tag
        
*   Create tests for backend with images
    
    *   Feeds image into algorithm and expects the correct waste type
        

Victor:
-------

### Previous Week’s Goals

*   Continue working on transfer learning classifier
    
    *   See if it is a viable path for our app
        
    *   3 days
        
*   Continue working on testing/CI code for the backend.
    
    *   More of the backend has been completed, we should make sure that our testing code is keeping up with it
        
    *   2 days
        

### Progress and Issues

This week I’ve been training CV models and testing what works best. I initially started with the model that was built on top of the dataset we decided on using. Unfortunately that project is deprecated, and turns out runs on old libraries that have been completely changed in newer iterations. In particular it seems like changes to how TensorFlow and keras interact would require a complete refactoring of half the project in order to get the project back into a working state. Without guarantee of the accuracy of the model I decided to move on.

Luckily I was able to take the dataset from that project and convert it into a format that we can use. I made a test model from scratch on it, which while not having a good enough accuracy for our use case is easy to deploy and can serve as the model we use for the beta if need be. Since existing models don’t have the specificity that we need to accurately categorize trash, I’m working now on a transfer learning solution that should outperform the model built from scratch.

### Plans and Goals

*   Get a working transfer learning model 
    
    *   3 days
        
*   Integrate model with backend
    
    *   2 days
        

Julia:
------

### Previous Week’s Goals

*    I plan to refine the UI design. This may involve tweaking the layout, color scheme, or element placement for better user experience and alignment with backend functionalities.
    
*   Develop the main page of the app, which will feature a camera interface upon opening. (2/5)
    

### Progress and Issues

This week, I had a meeting with Sulaiman to collaborate on the frontend development. We further discussed refining the UI design, including layout adjustments, color scheme enhancements, and ensuring alignment with backend functionalities. Additionally, we worked on developing the main page of the app, which features a camera interface upon opening.

### Plans and Goals

*   For the upcoming week, my goals align with Sulaiman's and the team's overall objectives. Specifically, I aim to continue refining the UI design, incorporating any necessary tweaks for improved user experience and seamless integration with backend functionalities. 
    
*   I will focus on implementing the next elements of the UI, such as transitions to show captured photos in a separate interface with a loading screen, adding navigation buttons, and ensuring alignment across different device orientations. 
    
*   These tasks are scheduled to be completed by Thursday/Friday, in line with the team's timeline for the beta release.
